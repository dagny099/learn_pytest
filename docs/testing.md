# Testing Guide: Workout Dashboard

This guide serves both as documentation of our current test coverage and as a learning resource for understanding how to test data-focused Python applications effectively.

## Testing Philosophy

Our testing approach follows these key principles:
1. Tests should help us understand the code they're testing
2. Each test should have a clear purpose and teach us something
3. Test files mirror the structure of our application code
4. We test both happy paths and error cases

## Current Test Coverage and Learning Opportunities

### Database Component (tests/test_database.py)
```python
# Example of testing database connection with proper error handling
def test_database_connection_failure():
    """
    This test demonstrates how to:
    1. Handle database connection failures gracefully
    2. Verify error messages
    3. Use pytest's exception handling
    """
    with pytest.raises(DatabaseError) as exc_info:
        DatabaseConnection("invalid://connection/string")
    assert "Could not connect" in str(exc_info.value)
```

Current Coverage:
- âœ… Basic connection establishment
- âœ… Connection error handling
- âœ… Data retrieval for date ranges
- ðŸš§ Transaction handling (planned)
- ðŸš§ Connection pooling (planned)

Learning Focus:
- Understanding database mocking strategies
- Testing asynchronous database operations
- Managing test databases effectively

### Analytics Component (tests/test_analytics.py)
```python
# Example of testing data transformations
def test_weekly_aggregation():
    """
    This test shows how to:
    1. Create test data with known properties
    2. Verify aggregation logic
    3. Handle edge cases like week boundaries
    """
    data = create_test_workout_data()  # Helper function
    result = WorkoutAnalytics.aggregate_weekly(data)
    assert_dataframe_equals(result, expected_result)
```

Current Coverage:
- âœ… Weekly data aggregation
- âœ… Basic statistics calculation
- ðŸš§ Monthly/yearly aggregations (planned)
- ðŸš§ Trend analysis (planned)

Learning Focus:
- Testing pandas DataFrame operations
- Validating statistical calculations
- Handling time-based aggregations

### UI Component (tests/test_app.py)
```python
# Example of testing Streamlit components
def test_date_range_validation():
    """
    This test demonstrates:
    1. Mocking Streamlit session state
    2. Testing user input validation
    3. Verifying error messages
    """
    with st.mock():
        result = validate_date_range("2024-01-01", "2023-12-31")
        assert not result.is_valid
        assert "End date must be after start date" in result.error
```

Current Coverage:
- âœ… Error message display
- ðŸš§ Data visualization (in progress)
- ðŸš§ User input validation (planned)

Learning Focus:
- Testing Streamlit applications
- Verifying visualization logic
- Handling user interactions

## Running Tests

```bash
# Run all tests with detailed output
pytest -v

# Run tests for a specific component
pytest tests/test_database.py -v

# Run tests and generate coverage report
pytest --cov=src tests/ --cov-report=html
```

Understanding Test Output:
- PASSED (.) tests ran successfully
- FAILED (F) tests found problems
- ERRORS (E) indicate test execution problems
- SKIPPED (s) tests were marked to skip

## Test Categories and Their Purpose

### Unit Tests (tests/*.py)
Test individual components in isolation. These help us:
- Understand component behavior
- Catch bugs early
- Document expected behavior

### Integration Tests (tests/integration/*.py)
Test how components work together. These verify:
- Component interactions
- Data flow between parts
- End-to-end functionality

### Performance Tests (planned)
Will help us understand:
- Response times under load
- Resource usage patterns
- Scaling characteristics

## Adding New Tests

When adding functionality:

1. Start with the test:
```python
def test_new_feature():
    """
    Document what this test teaches us about the code.
    Explain any non-obvious testing techniques used.
    """
    # Arrange
    input_data = prepare_test_data()
    
    # Act
    result = feature_under_test(input_data)
    
    # Assert
    assert_expected_behavior(result)
```

2. Implement the feature
3. Run the full test suite
4. Update documentation

## Future Testing Goals

1. Enhance Coverage:
   - Add property-based testing for data validation
   - Implement integration test suite
   - Add performance benchmarks

2. Improve Testing Infrastructure:
   - Set up continuous integration
   - Add automated test reporting
   - Implement test data generators

3. Educational Enhancements:
   - Add more test documentation
   - Create testing tutorials
   - Document testing patterns

Remember: Tests are not just validation tools; they're documentation and learning opportunities. Each test should teach us something about our code.